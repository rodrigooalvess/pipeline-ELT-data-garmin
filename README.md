# ğŸƒâ€â™‚ï¸ Garmin Data Pipeline: De Dados Brutos a Insights de Performance

Este projeto Ã© uma soluÃ§Ã£o completa de **ELT (Extract, Load, Transform)** projetada para automatizar a ingestÃ£o e anÃ¡lise de dados de atividades fÃ­sicas exportadas do Garmin. O pipeline transforma arquivos CSV brutos em uma camada analÃ­tica pronta para BI, utilizando as melhores prÃ¡ticas de Engenharia de Dados.



## ğŸ¯ Objetivo
Automatizar o processamento de mÃ©tricas de corrida (Pace, DistÃ¢ncia, FC), garantindo a qualidade dos dados atravÃ©s de testes automatizados e orquestraÃ§Ã£o profissional com Prefect.

## ğŸ› ï¸ Tecnologias Utilizadas
* **Linguagem:** Python 3.13+
* **Gerenciamento de DependÃªncias:** Poetry
* **Banco de Dados:** PostgreSQL
* **TransformaÃ§Ã£o de Dados:** dbt (Data Build Tool)
* **OrquestraÃ§Ã£o:** Prefect
* **Qualidade:** dbt-tests

---

## ğŸ—ï¸ Arquitetura de Dados
O projeto segue a arquitetura medalhÃ£o:
1.  **Landing:** Arquivos CSV brutos recebidos na pasta `data/landing`.
2.  **Raw (Bronze):** Dados ingeridos via Python sem transformaÃ§Ãµes no schema `raw`.
3.  **Analytics (Silver/Gold):** Dados limpos, tipados e agregados via dbt no schema `analytics`.

---

## ğŸš€ Como Executar o Projeto

### 1. PrÃ©-requisitos
* PostgreSQL instalado localmente.
* Poetry instalado (`pip install poetry`).

### 2. ConfiguraÃ§Ã£o do Banco de Dados
No seu PostgreSQL, crie um banco de dados e os schemas necessÃ¡rios:
```sql
CREATE DATABASE garmin_db;

-- Conecte ao banco e crie os schemas
CREATE SCHEMA raw;
CREATE SCHEMA analytics;
```

### 3. ExecuÃ§Ã£o do Pipeline
Para processar os dados, insira seus arquivos `.csv` na pasta `data/landing` e execute o comando:

> **Dica:** JÃ¡ deixei um arquivo de exemplo dentro da pasta `data/landing` para que vocÃª possa testar o pipeline imediatamente! ğŸš€

```bash
poetry run python main.py